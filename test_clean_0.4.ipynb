{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST fully connected two hidden layers.\n",
    "# Proper implementation of Fisher info estimation.\n",
    "\n",
    "# Data loading\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Network\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# Standard\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Parameters\n",
    "N_task = 2                  # Number of tasks\n",
    "N_epoch = 1               # Number of epochs\n",
    "batch_size = 100            # Number of samples in each minibatch\n",
    "hidden_size = 50           # Number of hidden layer neurons\n",
    "hidden1_dropout_prob = 0  # First hidden layer dropout probability\n",
    "hidden2_dropout_prob = 0  # Second hidden layer dropout probability\n",
    "lambda_L2 = 0.025           # Regularization parameter for L2\n",
    "lambda_EWC = 5000              # Regularization parameter for EWC\n",
    "sample_size_Fish = 1024    # Number of samples to use to estimate Fisher\n",
    "\n",
    "# Miscellaneous options\n",
    "use_cuda = 1\n",
    "num_rec = 2000              # How often to record/display test accuracies, running loss, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST-specific settings\n",
    "# Height and width of images\n",
    "height = 28\n",
    "width = 28\n",
    "# Number of labels\n",
    "num_labels = 10\n",
    "# Labels (for display purposes)\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "\n",
    "# Permutate pixels\n",
    "def permutate(image, permutation):\n",
    "    # c = number of channels (e.g. 3 for RGB)\n",
    "    # h = height\n",
    "    # w = width\n",
    "    c, h, w = image.size()\n",
    "    \n",
    "    image = image.view(-1,c)        # Resize to 1D array\n",
    "    image = image[permutation, :]   # Apply permutation\n",
    "    image = image.view(c, h, w)     # Resize to original shape\n",
    "    return image\n",
    "\n",
    "# Generate random permutations\n",
    "perms = []\n",
    "perms.append(np.arange(height*width))  # Non-permuted\n",
    "for i in range(N_task-1):\n",
    "    perms.append(np.random.permutation(perms[0]))\n",
    "    \n",
    "# Define transform\n",
    "def trans(permutation):\n",
    "    # Transforms (convert to tensor, normalize [0,1] -> [-1,1], apply permutation)\n",
    "    # mean = 0.5, std = 0.5 => subtract 0.5 from each pixel and divide by 2\n",
    "    # 3-tuple for 3 channels\n",
    "    return transforms.Compose([ \\\n",
    "            transforms.ToTensor(), \\\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)), \\\n",
    "            transforms.Lambda(lambda x: permutate(x, permutation))])\n",
    "        \n",
    "# Train datasets\n",
    "trainsets = [torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=trans(perm)) for perm in perms]\n",
    "    \n",
    "# Test datasets\n",
    "testsets = [torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=trans(perm)) for perm in perms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5bd4810668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4          1          5          9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu6IoSsbQhl1RFCVjaMOuKIqSMf4fObczAVjwMcYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5bd47e7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5          2          6          6\n"
     ]
    }
   ],
   "source": [
    "# Number of samples to display per task\n",
    "batch_size_sample = 4\n",
    "\n",
    "# Train dataset loaders\n",
    "trainloaders_sample = []\n",
    "for i in range(N_task):\n",
    "    trainloaders_sample.append(torch.utils.data.DataLoader(trainsets[i], batch_size=batch_size_sample, shuffle=True,num_workers=2))\n",
    "\n",
    "# Show image\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5   # Unnormalize ([-1,1] -> [0,1])\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    \n",
    "for i in range(N_task):\n",
    "    trainloader_sample = trainloaders_sample[i]\n",
    "    \n",
    "    dataiter = iter(trainloader_sample)     # Convert to iterator\n",
    "    images, labels = dataiter.next()        # Get next minibatch\n",
    "    \n",
    "    #if i==1:\n",
    "    #    print(images.size())\n",
    "    \n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    plt.show()\n",
    "    \n",
    "    # Show labels\n",
    "    print(' '.join('%10s' % classes[labels[j]] for j in range(batch_size_sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_size=400, hidden1_dropout_prob=0.2, hidden2_dropout_prob=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc1_drop = nn.Dropout(p=hidden1_dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2_drop = nn.Dropout(p=hidden2_dropout_prob)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Vanilla\n",
    "net = Net(\n",
    "    input_dim = height*width, \\\n",
    "    output_dim = num_labels, \\\n",
    "    hidden_size = hidden_size, \\\n",
    "    hidden1_dropout_prob = hidden1_dropout_prob, \\\n",
    "    hidden2_dropout_prob = hidden2_dropout_prob)\n",
    "\n",
    "net_L2 = copy.deepcopy(net)\n",
    "net_EWC = copy.deepcopy(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "optimizer_L2 = optim.SGD(net_L2.parameters(), lr=0.001)\n",
    "optimizer_EWC = optim.SGD(net_EWC.parameters(),lr=0.001)\n",
    "\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "#optimizer_L2 = optim.Adam(net_L2.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "#optimizer_EWC = optim.Adam(net_EWC.parameters(),lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_acc(net, dataset, input_dim, disp=False):\n",
    "    net.eval()  # Switch to eval mode (disable dropout layer)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.view(-1,input_dim) # First dim is batch_size\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0) # Batch size\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "    acc = correct/total\n",
    "        \n",
    "    if disp:\n",
    "        print('Accuracy of the network on the 10000 test images: %d %%' % (100* acc))\n",
    "        \n",
    "    net.train() # Revert to train mode\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_Fisher(net, dataset, sample_size = 1024):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True,num_workers=2)\n",
    "    \n",
    "    # Preallocate\n",
    "    Fisher = [torch.zeros(x.size()) for x in list(net.parameters())]\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Fisher = [x.cuda() for x in Fisher]\n",
    "    \n",
    "    # Take expectation over log-derivative squared\n",
    "    num_sampled = 0 # Counter for number of samples so far\n",
    "    for data, label in dataloader:\n",
    "        data = data.view(1, -1)\n",
    "\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        # Sample log likelihood\n",
    "\n",
    "        net.eval()      # Disable dropout layer\n",
    "        output = net(data)\n",
    "        net.train()     # Enable dropout layer\n",
    "        \n",
    "        prob = F.softmax(net(data))\n",
    "        \n",
    "        y_sample = torch.multinomial(prob).data # Sample from model\n",
    "        \n",
    "        #y_sample = label.data  # Given by data\n",
    "        \n",
    "        logL = F.log_softmax(output)[range(1),y_sample]\n",
    "        \n",
    "        # First derivative\n",
    "        logL_grad = autograd.grad(logL, net.parameters())\n",
    "        \n",
    "        # Squared & convert to tensor\n",
    "        logL_grad_sq = [x.data**2 for x in logL_grad]\n",
    "        \n",
    "        # Accumulate Fisher\n",
    "        for i in range(len(logL_grad_sq)):\n",
    "            Fisher[i] += logL_grad_sq[i]\n",
    "        \n",
    "        num_sampled += 1\n",
    "        if num_sampled >= sample_size:\n",
    "            break\n",
    "            \n",
    "    # Average\n",
    "    for i in range(len(Fisher)):\n",
    "        Fisher[i] /= sample_size\n",
    "\n",
    "    return Fisher\n",
    "\n",
    "def calc_EWC_loss(net, fixed, Fisher):\n",
    "    losses = []\n",
    "    \n",
    "    for p1, p2, Fish in zip(net.parameters(),fixed,Fisher):\n",
    "        losses.append((Fish * (p1 - p2)**2).sum())\n",
    "        \n",
    "    return sum(losses)\n",
    "\n",
    "def calc_L2_loss(net, fixed):\n",
    "    losses = []\n",
    "\n",
    "    for p1, p2 in zip(net.parameters(),fixed):\n",
    "        \n",
    "        losses.append(((p1 - p2)**2).sum())\n",
    "    \n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:109: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/david/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:110: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/david/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:111: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.069 (Vanilla) 2.069 (L2) 2.069 (EWC), time: 5 s\n"
     ]
    }
   ],
   "source": [
    "# Record accuracy\n",
    "time_list = []\n",
    "\n",
    "# Each \"lists\" contains N_task lists that record train accuracy\n",
    "acc_lists_t = [[] for i in range(N_task)]\n",
    "acc_L2_lists_t = [[] for i in range(N_task)]\n",
    "acc_EWC_lists_t = [[] for i in range(N_task)]\n",
    "\n",
    "# Each \"lists\" contains N_task lists that record test accuracy\n",
    "acc_lists = [[] for i in range(N_task)]\n",
    "acc_L2_lists = [[] for i in range(N_task)]\n",
    "acc_EWC_lists = [[] for i in range(N_task)]\n",
    "\n",
    "# Record trained models after each task\n",
    "param_list_L2 = []\n",
    "param_list_EWC = []\n",
    "Fisher_list = []\n",
    "Fisher_sum = []\n",
    "\n",
    "# CUDA\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "    net_L2 = net_L2.cuda()\n",
    "    net_EWC = net_EWC.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "\n",
    "t_start = time.time()   # Record total runtime\n",
    "t_part1 = t_start        # Record partial runtime\n",
    "for task in range(len(trainsets)):\n",
    "    trainset = trainsets[task]\n",
    "    testset = testsets[task]\n",
    "    for epoch in range(N_epoch):\n",
    "        # Reset running loss\n",
    "        running_loss = 0.0\n",
    "        running_loss_L2 = 0.0\n",
    "        running_loss_EWC = 0.0\n",
    "        \n",
    "        # Set up training data\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True,num_workers=2)\n",
    "        \n",
    "        # Iterate through all train data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                \n",
    "            # Resize input as 1D array\n",
    "            inputs = inputs.view(-1,height*width)\n",
    "            \n",
    "            # Vanilla\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward\n",
    "            outputs = net(inputs)\n",
    "            # Backward\n",
    "            original_loss = criterion(outputs, labels)\n",
    "            loss = original_loss\n",
    "            loss.backward()\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "            \n",
    "            # L2 regularization\n",
    "            # Zero the parameter gradients\n",
    "            optimizer_L2.zero_grad()\n",
    "            # Forward\n",
    "            outputs_L2 = net_L2(inputs)\n",
    "            # Backward\n",
    "            original_loss_L2 = criterion(outputs_L2, labels)\n",
    "            L2_loss = torch.zeros([],requires_grad=True)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                L2_loss = L2_loss.cuda()\n",
    "            # Single penalty\n",
    "            #if task > 0:\n",
    "            #    L2_loss = L2_loss + calc_L2_loss(net_L2, param_list_L2[task-1])\n",
    "            # Multiple penalties\n",
    "            for t_num in range(task):\n",
    "                L2_loss = L2_loss + calc_L2_loss(net_L2, param_list_L2[t_num])\n",
    "            \n",
    "            loss_L2 = original_loss_L2 + 0.5*lambda_L2*L2_loss\n",
    "            loss_L2.backward()\n",
    "            # Optimize\n",
    "            optimizer_L2.step()\n",
    "            \n",
    "            # EWC\n",
    "            # Zero the parameter gradients\n",
    "            optimizer_EWC.zero_grad()\n",
    "            # Forward\n",
    "            outputs_EWC = net_EWC(inputs)\n",
    "            # Backward\n",
    "            original_loss_EWC = criterion(outputs_EWC, labels)\n",
    "            EWC_loss = torch.zeros([], requires_grad = True)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                EWC_loss = EWC_loss.cuda()\n",
    "            # Single penalty\n",
    "            #if task > 0:\n",
    "            #    EWC_loss = EWC_loss + calc_EWC_loss(net_EWC, param_list_EWC[task-1], Fisher_sum)\n",
    "            # Multiple penalties\n",
    "            for t_num in range(task):\n",
    "                EWC_loss = EWC_loss + calc_EWC_loss(net_EWC, param_list_EWC[t_num],Fisher_list[t_num])\n",
    "            \n",
    "            loss_EWC = original_loss_EWC + 0.5*lambda_EWC*EWC_loss\n",
    "            loss_EWC.backward()\n",
    "            # Optimize\n",
    "            optimizer_EWC.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            running_loss_L2 += loss_L2.data[0]\n",
    "            running_loss_EWC += loss_EWC.data[0]\n",
    "            if (i % num_rec) == (num_rec-1): # Print every num_rec mini-batches\n",
    "            \n",
    "                t_part2 = time.time()\n",
    "            \n",
    "                print('[%d, %5d] loss: %.3f (Vanilla) %.3f (L2) %.3f (EWC), time: %.0f s' % (epoch+1,i+1,running_loss/num_rec,running_loss_L2/num_rec,running_loss_EWC/num_rec,t_part2 - t_part1))\n",
    "                \n",
    "                t_part1 = t_part2\n",
    "                \n",
    "                # Reset running loss\n",
    "                running_loss = 0.0\n",
    "                running_loss_L2 = 0.0\n",
    "                running_loss_EWC = 0.0\n",
    "                \n",
    "                # Record test accuracies for each task\n",
    "                for j in range(N_task):\n",
    "                    acc_lists_t[j].append(test_acc(net, trainsets[j], height*width))           # Vanilla\n",
    "                    acc_L2_lists_t[j].append(test_acc(net_L2, trainsets[j], height*width))     # L2\n",
    "                    acc_EWC_lists_t[j].append(test_acc(net_EWC, trainsets[j], height*width))   # EWC\n",
    "                    \n",
    "                    acc_lists[j].append(test_acc(net, testsets[j], height*width))           # Vanilla\n",
    "                    acc_L2_lists[j].append(test_acc(net_L2, testsets[j], height*width))     # L2\n",
    "                    acc_EWC_lists[j].append(test_acc(net_EWC, testsets[j], height*width))   # EWC\n",
    "    \n",
    "    # Save models trained on the current task\n",
    "    current_param_L2 = copy.deepcopy(list(net_L2.parameters()))\n",
    "    param_list_L2.append(current_param_L2)\n",
    "    \n",
    "    current_param_EWC = copy.deepcopy(list(net_EWC.parameters()))\n",
    "    param_list_EWC.append(current_param_EWC)\n",
    "    \n",
    "    # Calculate Fisher Info. for EWC\n",
    "    Fisher = calc_Fisher(net_EWC,testset,sample_size_Fish)\n",
    "    # Record Fisher (for multiple penalties)\n",
    "    Fisher_list.append(Fisher)\n",
    "    # Sum Fisher (for single penalty)\n",
    "    if task == 0:\n",
    "        Fisher_sum = copy.deepcopy(Fisher)\n",
    "    else:\n",
    "        for i in range(len(Fisher)):\n",
    "            Fisher_sum[i] += Fisher[i]\n",
    "      \n",
    "t_finish = time.time()\n",
    "\n",
    "print('Finished Training')\n",
    "print('Training time: ' + str(t_finish-t_start) + ' s')\n",
    "\n",
    "# Convert to arrays\n",
    "for j in range(N_task):\n",
    "    acc_lists[j] = np.array(acc_lists[j])\n",
    "    acc_L2_lists[j] = np.array(acc_L2_lists[j])\n",
    "    acc_EWC_lists[j] = np.array(acc_EWC_lists[j])\n",
    "time_list = np.arange(len(acc_lists[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Colormap for separate tasks\n",
    "colormap = plt.cm.jet\n",
    "colors = [colormap(i) for i in np.linspace(0,1,N_task)]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Vanilla\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Vanilla')\n",
    "for j in range(N_task):\n",
    "    plt.plot(time_list, acc_lists_t[j], label = 'Task ' + str(j+1), c=colors[j])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Training time')\n",
    "plt.ylabel('Train accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# L2\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('L2')\n",
    "for j in range(N_task):\n",
    "    plt.plot(time_list, acc_L2_lists_t[j], label = 'Task ' + str(j+1), c=colors[j])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Training time')\n",
    "plt.legend()\n",
    "\n",
    "# EWC\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('EWC')\n",
    "for j in range(N_task):\n",
    "    plt.plot(time_list, acc_EWC_lists_t[j], label = 'Task ' + str(j+1), c=colors[j])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Training time')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Colormap for separate tasks\n",
    "colormap = plt.cm.jet\n",
    "colors = [colormap(i) for i in np.linspace(0,1,N_task)]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Vanilla\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Vanilla')\n",
    "for j in range(N_task):\n",
    "    plt.plot(time_list, acc_lists[j], label = 'Task ' + str(j+1), c=colors[j])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Training time')\n",
    "plt.ylabel('Test accuracy')\n",
    "#plt.legend()\n",
    "\n",
    "# L2\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('L2')\n",
    "for j in range(N_task):\n",
    "    plt.plot(time_list, acc_L2_lists[j], label = 'Task ' + str(j+1), c=colors[j])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Training time')\n",
    "#plt.legend()\n",
    "\n",
    "# EWC\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('EWC')\n",
    "for j in range(N_task):\n",
    "    plt.plot(time_list, acc_EWC_lists[j], label = 'Task ' + str(j+1), c=colors[j])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Training time')\n",
    "#plt.legend()\n",
    "\n",
    "plt.savefig('noleg_new_multiple_pen_10_epochs_H=' + str(hidden_size) + '_lambda_L2=' + str(lambda_L2) + '_lambda_EWC=' + str(lambda_EWC) + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot test averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_time = len(time_list)\n",
    "task_time = len(time_list)//N_task\n",
    "\n",
    "acc_avg = np.zeros(N_task)\n",
    "acc_L2_avg = np.zeros(N_task)\n",
    "acc_EWC_avg = np.zeros(N_task)\n",
    "\n",
    "for j in range(N_task):\n",
    "    for i in range(j+1):\n",
    "        acc_avg[j] += acc_lists[i][(j+1)*task_time-1]\n",
    "        acc_L2_avg[j] += acc_L2_lists[i][(j+1)*task_time-1]\n",
    "        acc_EWC_avg[j] += acc_EWC_lists[i][(j+1)*task_time-1]\n",
    "    acc_avg[j] /= (j+1)\n",
    "    acc_L2_avg[j] /= (j+1)\n",
    "    acc_EWC_avg[j] /= (j+1)\n",
    "    \n",
    "plt.figure()\n",
    "plt.title('Test accuracy (averaged over all learned tasks)')\n",
    "plt.plot(acc_avg, label = 'Vanilla',c='r')\n",
    "plt.plot(acc_L2_avg, label = 'L2',c='b')\n",
    "plt.plot(acc_EWC_avg, label = 'EWC',c='g')\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Task')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('N_task=' + str(N_task) + 'new_multiple_pen_10_epochs_H=' + str(hidden_size) + '_lambda_L2=' + str(lambda_L2) + '_lambda_EWC=' + str(lambda_EWC) + '_avg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for p1,p2 in zip(net_L2.parameters(),blah):\n",
    "    losses.append(((p1-p2)**2).sum())\n",
    "losses\n",
    "sum(losses)\n",
    "\n",
    "calc_L2_loss(net_L2,blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True,num_workers=2)\n",
    "for a,b in dataloader:\n",
    "    a = a.view(1,-1)\n",
    "    a = Variable(a)\n",
    "    b = Variable(b)\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "    net.eval()\n",
    "    #print(F.softmax(net(a)))\n",
    "    prob = F.softmax(net(a))\n",
    "    logL = F.log_softmax(net(a))[range(1),b.data]\n",
    "    net.train()\n",
    "    \n",
    "    #a = net(a).data.max(1)[1]\n",
    "    a=net(a)\n",
    "    print(a.data.max(1)[1][0])\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F.log_softmax(net(a))[range(1),b.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.log_softmax(net(a))[range(1),torch.multinomial(prob).data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fisher[5].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
